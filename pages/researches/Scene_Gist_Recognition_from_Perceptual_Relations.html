<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Scene Gist Recognition from Perceptual Relations</title>
    <base href="/ICVL/">
    <link rel="stylesheet" href="css/all.css">
</head>
<body>
    <div id="header-placeholder"></div>
    <div class="main-container">
        <main id="content">
            <section class="research-section">
                <h2>Scene Gist Recognition from Perceptual Relations</h2>

                <img src="./assets/research/Scene-Gist-Recognition-from-Perceptual-Relations/gist.gif" alt="Scene Gist Recognition Image" width="400" height="300">

                <p>Humans have this remarkable ability to comprehend visual scenes rapidly and accurately. Whether we quickly change television channels, browse photo albums, or simply try to cross the road, our visual system is working with superb efficiency, accuracy, and speed to extract the meaning of each scene. Examine the rapid sequence of scenes on the right. Is it fair to say that you can indeed grasp the gist of most?</p>

                <p>But what characterizes visual processing underlying this visual categorization process? In this project, we focus on one aspect of this question related to prior knowledge about the perceptual relations between the different scene categories. To date, computational algorithms for scene categorization rarely consider the possible effect of such perceptual relations. However, even intuitively, when our visual system observes a bedroom scene for a fraction of a second and “deliberates” how to categorize it, what possibly comes to mind in addition to “bedroom” are perhaps classes like “living room” or “kitchen”. It appears as if our visual system does not even consider possibilities such as “coast” or “highway”, or more generally, scenes that are perceptually “distant” from the observable reference class. Put differently, prior knowledge about the perceptual relations between the different categories of scenes may help facilitate better, more efficient, and faster categorization.</p>

                <h2>Online Experiment</h2>

                <p><a href="http://www.cs.bgu.ac.il/~vision/pmc"><img src="./assets/research/Scene-Gist-Recognition-from-Perceptual-Relations/main_root.png" alt="Play and Contribute" width="321" height="194"></a></p>
                <p>The formal manifestation of the basic idea described above requires the extraction of the perceptual relations between scene classes. While we use controlled lab experiments to collect these data for a small number of classes (see papers), doing the same with larger sets becomes infeasible without an enormous number of subjects, something that may only be possible by harnessing the power of the web. We, therefore, invite you to play our perceptual game and contribute to this data collection in a Pair-Matching Categorization (PMC) experiment. Please click on the image above to begin. Please note that the web-based experiment requires a web browser and just 4-5 short minutes of your time. (Unfortunately, at this point the software is supported on Windows platforms only). We greatly appreciate your participation and we thank you for helping the collection of these data.</p>

                <h2>Download Papers and Presentations</h2>
                <ul>
                    <li>I. Kadar, and O. Ben-Shahar, <a href="https://www.cs.bgu.ac.il/~ben-shahar/Publications/2012-CVPR-Small_Sample_Scene_Categorization_from_Perceptual_Relations.pdf">Small Sample Scene Categorization from Perceptual Relations</a>, In the <a href="http://www.cvpr2012.org/">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</a>, Providence, Rhode Island, 2012.</li>
                    <li>I. Kadar, and O. Ben-Shahar, <a href="https://www.cs.bgu.ac.il/~icvl/projects/project-gist.html">Learning perceptual relations for categorizing natural scenes from few training examples</a>, In the <a href="http://www.cs.bgu.ac.il/~icvl/projects/project-gist.html">Annual meeting of the Vision Science Society (VSS)</a>, Naples, Florida, 2012.</li>
                    <li>I. Kadar, and O. Ben-Shahar, <a href="https://www.journalofvision.org/content/11/11/1113">A new perceptual paradigm and psychophysical evidence for hierarchical gist recognition</a>, In the <a href="http://www.journalofvision.org/content/11/11.toc">Annual meeting of the Vision Science Society (VSS)</a>, Naples, Florida, 2011.</li>
                </ul>

                <h2>Acknowledgments</h2>
                <p>This project is a joint work by Ilan Kadar and <a href="http://www.cs.bgu.ac.il/~obs/">Ohad Ben-Shahar</a> of the <a href="https://www.cs.bgu.ac.il/">Computer Science Department</a>, <a href="https://in.bgu.ac.il/en/Pages/default.aspx">Ben-Gurion University of The Negev</a>, <a href="http://en.wikipedia.org/wiki/Beersheba">Beer Sheva</a>, <a href="http://en.wikipedia.org/wiki/Israel">Israel</a>. Different parts of it have been presented in various computational and biological vision conferences, including the <a href="http://cvpr2012.org/">CVPR 2012</a>, VSS 2011, and VSS 2012.</p>
                <p>The research was funded in part by the European Commission in the 7th Framework Programme (CROPS GA no 246252). We also thank the generous support of the Frankel fund, the Paul Ivanier center for Robotics Research, and the Zlotowski Center for Neuroscience at Ben-Gurion University.</p>
            </section>
        </main>
    </div>
    <div id="footer-placeholder"></div>
    <script src="/ICVL/js/loadContent.js"></script>
</body>
</html>
